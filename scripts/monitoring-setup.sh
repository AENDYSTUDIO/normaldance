#!/bin/bash

# NormalDance Monitoring and Logging Setup Script
# This script sets up monitoring and logging infrastructure for NormalDance

set -e

# Configuration
NAMESPACE="production"
CLUSTER_NAME="normaldance-prod"
REGION="us-east-1"
GRAFANA_ADMIN_PASSWORD="admin123"
PROMetheus_RETENTION="30d"
LOKI_RETENTION="7d"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Logging function
log() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

# Check prerequisites
check_prerequisites() {
    log "Checking prerequisites..."
    
    # Check if kubectl is installed
    if ! command -v kubectl &> /dev/null; then
        error "kubectl is not installed"
    fi
    
    # Check if helm is installed
    if ! command -v helm &> /dev/null; then
        error "helm is not installed"
    fi
    
    # Check if aws-cli is installed
    if ! command -v aws &> /dev/null; then
        error "aws-cli is not installed"
    fi
    
    log "All prerequisites are installed"
}

# Configure AWS credentials
configure_aws() {
    log "Configuring AWS credentials..."
    
    # Check if AWS credentials are set
    if [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ]; then
        error "AWS credentials not set. Please set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables"
    fi
    
    # Configure AWS CLI
    aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
    aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
    aws configure set region $REGION
    
    log "AWS credentials configured"
}

# Connect to Kubernetes cluster
connect_to_cluster() {
    log "Connecting to Kubernetes cluster..."
    
    # Get cluster credentials
    aws eks update-kubeconfig --name $CLUSTER_NAME --region $REGION
    
    # Verify connection
    if ! kubectl cluster-info &> /dev/null; then
        error "Failed to connect to Kubernetes cluster"
    fi
    
    log "Connected to Kubernetes cluster"
}

# Add Helm repositories
add_helm_repositories() {
    log "Adding Helm repositories..."
    
    # Add Prometheus Helm repository
    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
    helm repo update
    
    # Add Grafana Helm repository
    helm repo add grafana https://grafana.github.io/helm-charts
    helm repo update
    
    # Add Loki Helm repository
    helm repo add grafana https://grafana.github.io/helm-charts
    helm repo update
    
    log "Helm repositories added"
}

# Install Prometheus
install_prometheus() {
    log "Installing Prometheus..."
    
    # Create namespace for monitoring
    kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
    
    # Install Prometheus
    helm upgrade --install prometheus prometheus-community/kube-prometheus-stack \
        --namespace monitoring \
        --set grafana.adminPassword=$GRAFANA_ADMIN_PASSWORD \
        --set prometheus.prometheusSpec.retention=$PROMetheus_RETENTION \
        --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=10Gi \
        --set prometheus.prometheusSpec.podMonitorSelectorNilUsesHelmValues=false \
        --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false \
        --set prometheus.prometheusSpec.podMonitorSelector.matchExpressions[0].key=app \
        --set prometheus.prometheusSpec.podMonitorSelector.matchExpressions[0].values[0]=normaldance \
        --set prometheus.prometheusSpec.serviceMonitorSelector.matchExpressions[0].key=app \
        --set prometheus.prometheusSpec.serviceMonitorSelector.matchExpressions[0].values[0]=normaldance \
        --wait \
        --timeout=600s
    
    log "Prometheus installed"
}

# Install Loki
install_loki() {
    log "Installing Loki..."
    
    # Install Loki
    helm upgrade --install loki grafana/loki \
        --namespace monitoring \
        --set config.loki.storage.type=s3 \
        --set config.loki.storage.s3.bucket=normaldance-logs \
        --set config.loki.storage.s3.endpoint=s3.amazonaws.com \
        --set config.loki.storage.s3.region=$REGION \
        --set config.loki.storage.s3.access_key_id=$AWS_ACCESS_KEY_ID \
        --set config.loki.storage.s3.secret_access_key=$AWS_SECRET_ACCESS_KEY \
        --set config.loki.storage.s3.insecure=false \
        --set config.loki.storage.s3.prefix=loki \
        --set config.loki.retention=$LOKI_RETENTION \
        --set config.loki.chunk_store_config.max_look_back_period=720h \
        --set config.loki.schema_config.configs[0].from=2020-01-01 \
        --set config.loki.schema_config.configs[0].store=tsdb \
        --set config.loki.schema_config.configs[0].object_store=s3 \
        --set config.loki.schema_config.configs[0].schema=v11 \
        --set config.loki.schema_config.configs[0].index.prefix_=index_ \
        --set config.loki.schema_config.configs[0].index.period=24h \
        --wait \
        --timeout=600s
    
    log "Loki installed"
}

# Install Grafana
install_grafana() {
    log "Installing Grafana..."
    
    # Install Grafana
    helm upgrade --install grafana grafana/grafana \
        --namespace monitoring \
        --set adminPassword=$GRAFANA_ADMIN_PASSWORD \
        --set service.type=LoadBalancer \
        --set service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-type"="nlb" \
        --set service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-cross-zone-load-balancing-enabled"="true" \
        --set persistence.enabled=true \
        --set persistence.size=10Gi \
        --set persistence.storageClassName=gp2 \
        --set datasources.datasources.yaml '{"apiVersion": 1, "datasources": [{"access": "proxy", "editable": false, "name": "Prometheus", "orgId": 1, "type": "prometheus", "url": "http://prometheus-prometheus-kube-prometheus-prometheus.monitoring.svc.cluster.local:9090", "version": 1}]}' \
        --set dashboards."default".datasources.prometheus="Prometheus" \
        --wait \
        --timeout=600s
    
    log "Grafana installed"
}

# Install Fluentd for logging
install_fluentd() {
    log "Installing Fluentd..."
    
    # Create namespace for logging
    kubectl create namespace logging --dry-run=client -o yaml | kubectl apply -f -
    
    # Install Fluentd
    kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: logging
  labels:
    app: fluentd
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      containers:
      - name: fluentd
        image: fluent/fluentd:v1.16-1
        resources:
          limits:
            memory: 512Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: config-volume
          mountPath: /fluentd/etc
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: config-volume
        configMap:
          name: fluentd-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: logging
data:
  fluent.conf: |
    <source>
      @type tail
      path /var/log/containers/*normaldance*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag normaldance.*
      format json
      time_format %Y-%m-%dT%H:%M:%S.%NZ
    </source>
    
    <source>
      @type tail
      path /var/log/containers/*kube-system*.log
      pos_file /var/log/fluentd-kube-system.log.pos
      tag kube-system.*
      format json
      time_format %Y-%m-%dT%H:%M:%S.%NZ
    </source>
    
    <match normaldance.**>
      @type loki
      host: loki.logging.svc.cluster.local
      port: 3100
      label_keys level,message
      extract_keys timestamp
      <buffer>
        flush_mode interval
        flush_interval 5s
        chunk_limit_size 2M
      </buffer>
    </match>
    
    <match kube-system.**>
      @type loki
      host: loki.logging.svc.cluster.local
      port: 3100
      label_keys level,message
      extract_keys timestamp
      <buffer>
        flush_mode interval
        flush_interval 5s
        chunk_limit_size 2M
      </buffer>
    </match>
EOF
    
    log "Fluentd installed"
}

# Install Prometheus Operator
install_prometheus_operator() {
    log "Installing Prometheus Operator..."
    
    # Install Prometheus Operator
    helm upgrade --install prometheus-operator prometheus-community/kube-prometheus-operator \
        --namespace monitoring \
        --set prometheusOperator.createCustomResource=false \
        --wait \
        --timeout=600s
    
    log "Prometheus Operator installed"
}

# Create ServiceMonitors
create_servicemonitors() {
    log "Creating ServiceMonitors..."
    
    # Create ServiceMonitor for NormalDance API
    kubectl apply -f - <<EOF
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: normaldance-api
  namespace: monitoring
  labels:
    app: normaldance
spec:
  selector:
    matchLabels:
      app: normaldance-api
  endpoints:
  - port: web
    interval: 30s
    path: /metrics
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: normaldance-websocket
  namespace: monitoring
  labels:
    app: normaldance
spec:
  selector:
    matchLabels:
      app: normaldance-websocket
  endpoints:
  - port: websocket
    interval: 30s
    path: /metrics
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: normaldance-redis
  namespace: monitoring
  labels:
    app: normaldance
spec:
  selector:
    matchLabels:
      app: normaldance-redis
  endpoints:
  - port: redis
    interval: 30s
    path: /metrics
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: normaldance-database
  namespace: monitoring
  labels:
    app: normaldance
spec:
  selector:
    matchLabels:
      app: normaldance-database
  endpoints:
  - port: postgresql
    interval: 30s
    path: /metrics
EOF
    
    log "ServiceMonitors created"
}

# Create Grafana dashboards
create_grafana_dashboards() {
    log "Creating Grafana dashboards..."
    
    # Create NormalDance dashboard
    kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: normaldance-dashboard
  namespace: monitoring
data:
  normaldance-dashboard.json: |
    {
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": "-- Grafana --",
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "gnetId": null,
      "graphTooltip": 0,
      "id": null,
      "links": [],
      "panels": [
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 0
          },
          "hiddenSeries": false,
          "id": 1,
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "rate(http_requests_total[5m])",
              "legendFormat": "{{method}} {{route}}",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "HTTP Requests",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "req/s",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": 0,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        }
      ],
      "refresh": "5s",
      "schemaVersion": 26,
      "style": "dark",
      "tags": [
        "normaldance"
      ],
      "templating": {
        "list": []
      },
      "time": {
        "from": "now-1h",
        "to": "now"
      },
      "timepicker": {
        "refresh_intervals": [
          "5s",
          "10s",
          "30s",
          "1m",
          "5m",
          "15m",
          "30m",
          "1h",
          "2h",
          "6h",
          "12h",
          "1d",
          "7d",
          "30d"
        ]
      },
      "timezone": "",
      "title": "NormalDance Dashboard",
      "uid": "normaldance-dashboard",
      "version": 1
    }
EOF
    
    # Apply dashboard to Grafana
    kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards
  namespace: monitoring
data:
  normaldance-dashboard.json: |
    {
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": "-- Grafana --",
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "gnetId": null,
      "graphTooltip": 0,
      "id": null,
      "links": [],
      "panels": [
        {
          "aliasColors": {},
          "bars": false,
          "dashLength": 10,
          "dashes": false,
          "datasource": "Prometheus",
          "fill": 1,
          "fillGradient": 0,
          "gridPos": {
            "h": 8,
            "w": 12,
            "x": 0,
            "y": 0
          },
          "hiddenSeries": false,
          "id": 1,
          "legend": {
            "avg": false,
            "current": false,
            "max": false,
            "min": false,
            "show": true,
            "total": false,
            "values": false
          },
          "lines": true,
          "linewidth": 1,
          "nullPointMode": "null",
          "options": {
            "dataLinks": []
          },
          "percentage": false,
          "pointradius": 2,
          "points": false,
          "renderer": "flot",
          "seriesOverrides": [],
          "spaceLength": 10,
          "stack": false,
          "steppedLine": false,
          "targets": [
            {
              "expr": "rate(http_requests_total[5m])",
              "legendFormat": "{{method}} {{route}}",
              "refId": "A"
            }
          ],
          "thresholds": [],
          "timeFrom": null,
          "timeRegions": [],
          "timeShift": null,
          "title": "HTTP Requests",
          "tooltip": {
            "shared": true,
            "sort": 0,
            "value_type": "individual"
          },
          "type": "graph",
          "xaxis": {
            "buckets": null,
            "mode": "time",
            "name": null,
            "show": true,
            "values": []
          },
          "yaxes": [
            {
              "format": "req/s",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": 0,
              "show": true
            },
            {
              "format": "short",
              "label": null,
              "logBase": 1,
              "max": null,
              "min": null,
              "show": true
            }
          ],
          "yaxis": {
            "align": false,
            "alignLevel": null
          }
        }
      ],
      "refresh": "5s",
      "schemaVersion": 26,
      "style": "dark",
      "tags": [
        "normaldance"
      ],
      "templating": {
        "list": []
      },
      "time": {
        "from": "now-1h",
        "to": "now"
      },
      "timepicker": {
        "refresh_intervals": [
          "5s",
          "10s",
          "30s",
          "1m",
          "5m",
          "15m",
          "30m",
          "1h",
          "2h",
          "6h",
          "12h",
          "1d",
          "7d",
          "30d"
        ]
      },
      "timezone": "",
      "title": "NormalDance Dashboard",
      "uid": "normaldance-dashboard",
      "version": 1
    }
EOF
    
    log "Grafana dashboards created"
}

# Create AlertManager configuration
create_alertmanager_config() {
    log "Creating AlertManager configuration..."
    
    kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'localhost:587'
      smtp_from: 'alertmanager@normaldance.app'
      smtp_auth_username: 'alertmanager@normaldance.app'
      smtp_auth_password: '${ALERTMANAGER_SMTP_PASSWORD}'
    
    route:
      group_by: ['alertname']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'web.hook'
    
    receivers:
    - name: 'web.hook'
      webhook_configs:
      - url: 'http://alertmanager-webhook.monitoring.svc.cluster.local:5000/'
    
    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'dev', 'instance']
EOF
    
    log "AlertManager configuration created"
}

# Verify monitoring setup
verify_monitoring_setup() {
    log "Verifying monitoring setup..."
    
    # Check Prometheus pods
    kubectl get pods -n monitoring -l app=prometheus
    
    # Check Grafana pods
    kubectl get pods -n monitoring -l app=grafana
    
    # Check Loki pods
    kubectl get pods -n monitoring -l app=loki
    
    # Check Fluentd pods
    kubectl get pods -n logging -l app=fluentd
    
    # Get Grafana URL
    GRAFANA_URL=$(kubectl get service grafana -n monitoring -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
    if [ -n "$GRAFANA_URL" ]; then
        log "Grafana URL: http://$GRAFANA_URL"
        log "Username: admin"
        log "Password: $GRAFANA_ADMIN_PASSWORD"
    fi
    
    log "Monitoring setup verified"
}

# Main function
main() {
    log "Starting NormalDance monitoring setup..."
    
    # Check prerequisites
    check_prerequisites
    
    # Configure AWS
    configure_aws
    
    # Connect to cluster
    connect_to_cluster
    
    # Add Helm repositories
    add_helm_repositories
    
    # Install Prometheus Operator
    install_prometheus_operator
    
    # Install Prometheus
    install_prometheus
    
    # Install Loki
    install_loki
    
    # Install Grafana
    install_grafana
    
    # Install Fluentd
    install_fluentd
    
    # Create ServiceMonitors
    create_servicemonitors
    
    # Create Grafana dashboards
    create_grafana_dashboards
    
    # Create AlertManager configuration
    create_alertmanager_config
    
    # Verify monitoring setup
    verify_monitoring_setup
    
    log "Monitoring setup completed successfully!"
}

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --namespace)
            NAMESPACE="$2"
            shift 2
            ;;
        --cluster)
            CLUSTER_NAME="$2"
            shift 2
            ;;
        --region)
            REGION="$2"
            shift 2
            ;;
        --grafana-password)
            GRAFANA_ADMIN_PASSWORD="$2"
            shift 2
            ;;
        --prometheus-retention)
            PROMetheus_RETENTION="$2"
            shift 2
            ;;
        --loki-retention)
            LOKI_RETENTION="$2"
            shift 2
            ;;
        --help)
            echo "Usage: $0 [OPTIONS]"
            echo "Options:"
            echo "  --namespace NAMESPACE         Kubernetes namespace (default: production)"
            echo "  --cluster CLUSTER_NAME        EKS cluster name (default: normaldance-prod)"
            echo "  --region REGION               AWS region (default: us-east-1)"
            echo "  --grafana-password PASSWORD   Grafana admin password (default: admin123)"
            echo "  --prometheus-retention RET   Prometheus retention period (default: 30d)"
            echo "  --loki-retention RET         Loki retention period (default: 7d)"
            echo "  --help                       Show this help message"
            exit 0
            ;;
        *)
            error "Unknown option: $1"
            ;;
    esac
done

# Run main function
main "$@"